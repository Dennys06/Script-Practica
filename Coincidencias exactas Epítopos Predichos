import pandas as pd
import re


# Paso 1: Generar el diccionario de péptidos de alfa-sinucleína

# Definir la nueva secuencia de la proteína alfa-sinucleína
sequence = "MDVFMKGLSKAKEGVVAAAEKTKQGVAEAAGKTKEGVLYVGSKTKEGVVHGVATVAEKTKEQVTNVGGAVVTGVTAVAQKTVEGAGSIAAATGFVKKDQLGKNEEGAPQEGILEDMPVDPDNEAYEMPSEEGYQDYEPEA"

# Generar péptidos a partir de la secuencia
def generate_peptides(sequence, min_length=8, max_length=21):
    peptides = []
    seq_length = len(sequence)
    
    for length in range(min_length, max_length + 1):
        for start in range(seq_length - length + 1):
            peptide = sequence[start:start + length]
            peptides.append(peptide)
    
    return peptides

# Función para renombrar los péptidos
def rename_peptide(peptide_sequence, full_sequence):
    start_position = full_sequence.find(peptide_sequence)
    if start_position == -1:
        return "Not found"
    
    start_position += 1
    peptide_length = len(peptide_sequence)
    new_name = f"{start_position}P{peptide_length}pep"
    return new_name

# Generar péptidos y crear un DataFrame
peptides = generate_peptides(sequence)
data = {
    'New Name': [rename_peptide(peptide, sequence) for peptide in peptides],
    'Epitope - Name': peptides
}
df_peptides = pd.DataFrame(data)

# Guardar el DataFrame como archivo FASTA
output_fasta_path_1 = r"C:\Users\dennys\Desktop\Resultados oficiales\Peptidos AlphaSyn.fasta"

def save_as_fasta(df, output_fasta_path):
    with open(output_fasta_path, 'w') as fasta_file:
        for index, row in df.iterrows():
            new_name = row['New Name']
            sequence = row['Epitope - Name']
            fasta_file.write(f">{new_name}\n")
            fasta_file.write(f"{sequence}\n")

save_as_fasta(df_peptides, output_fasta_path_1)
print(f"Archivo FASTA guardado en: {output_fasta_path_1}")

# Convertir el archivo FASTA a diccionario y guardarlo como TXT
output_dict_path_1 = r"C:\Users\dennys\Desktop\Resultados oficiales\Peptidos AlphaSyn diccionario.txt"
diccionario_peptidos_1 = {}

with open(output_fasta_path_1, 'r') as archivo:
    nombre_peptido = None
    for linea in archivo:
        linea = linea.strip()
        if linea.startswith(">"):
            nombre_peptido = linea[1:]  # Guardar el nombre del péptido sin '>'
        else:
            diccionario_peptidos_1[nombre_peptido] = linea

# Guardar el diccionario en un archivo TXT
with open(output_dict_path_1, 'w') as archivo_txt:
    for nombre, secuencia in diccionario_peptidos_1.items():
        archivo_txt.write(f"{nombre}: {secuencia}\n")

print(f"El diccionario de péptidos se ha guardado en {output_dict_path_1}.")



#Paso 1: Filtrar por Rank menos o igual a 20
# Ruta del archivo Excel original
input_file = r"C:\Users\dennys\Desktop\Resultados oficiales MHC binding prediction\MHC II mouse.xlsx"

# Ruta del archivo de salida (con los datos filtrados)
output_file_filtrado = r"C:\Users\dennys\Desktop\Resultados oficiales MHC binding prediction\MHC II mouse filtrado.xlsx"

# Leer el archivo Excel
df = pd.read_excel(input_file)

# Filtrar los datos en donde la columna "rank" sea menor o igual a 20
df_filtrado = df[df['rank'] <= 20]

# Guardar el archivo filtrado en un nuevo Excel
df_filtrado.to_excel(output_file_filtrado, index=False)

print(f"Archivo filtrado y guardado como {output_file_filtrado}")

#Paso 2: Establecer nombre a cada secuencia
# Ruta del archivo Excel
excel_file_path = output_file_filtrado 

# Cargar el archivo Excel
df = pd.read_excel(excel_file_path)

# Imprimir las columnas para verificar sus nombres
print("Nombres de las columnas:", df.columns)

# Limpiar los nombres de las columnas
df.columns = df.columns.str.strip()

# Verificar nuevamente los nombres de las columnas
print("Nombres de las columnas después de limpiar:", df.columns)

# Función para eliminar modificaciones PTM
def clean_peptide_sequence(peptide_sequence):
    cleaned_sequence = re.sub(r'\+.*', '', peptide_sequence).strip()
    return cleaned_sequence

# Función para extraer las modificaciones PTM
def extract_ptm(peptide_sequence):
    ptm_match = re.search(r'\+\s*(.*)', peptide_sequence)
    if ptm_match:
        return ptm_match.group(1).strip()
    return ""

# Función para renombrar los péptidos con PTM y posición inicial
def rename_peptide_with_ptm_and_position(peptide_sequence, starting_position, peptide_dict):
    cleaned_peptide = clean_peptide_sequence(peptide_sequence)
    ptm = extract_ptm(peptide_sequence)
    peptide_length = len(cleaned_peptide)

    if pd.notna(starting_position):
        base_name = f"{int(starting_position)}P{peptide_length}pep"
    else:
        base_name = f"{peptide_length}pep"

    if ptm:
        base_name += ptm
    
    # Manejo de nombres duplicados
    if base_name in peptide_dict:
        peptide_dict[base_name] += 1
        new_name = f"{base_name}-{peptide_dict[base_name]}"
    else:
        peptide_dict[base_name] = 1
        new_name = base_name

    return new_name, cleaned_peptide

# Crear un diccionario para llevar el seguimiento de nombres
peptide_dict = {}

# Aplicar la función a cada fila del DataFrame
df[['New Name', 'Cleaned Sequence']] = df.apply(
    lambda row: pd.Series(rename_peptide_with_ptm_and_position(row['peptide'], row['start'], peptide_dict)),
    axis=1
)

# Guardar el archivo modificado como Excel
output_excel_path_renombrados = r"C:\Users\dennys\Desktop\Resultados oficiales MHC binding prediction\MHC II mouse renombrados.xlsx"
df.to_excel(output_excel_path_renombrados, index=False)
print(f"Archivo Excel guardado en: {output_excel_path_renombrados}")


# Generacion diccionario 
# Rutas de los archivos
input_file = r"C:\Users\dennys\Desktop\Resultados oficiales MHC binding prediction\MHC II mouse renombrados.xlsx"
fasta_output_file = r"C:\Users\dennys\Desktop\Resultados oficiales MHC binding prediction\MHC II mouse.fasta"
dict_output_file_epitopos = r"C:\Users\dennys\Desktop\Resultados oficiales MHC binding prediction\MHC II mouse diccionario.txt"

# Leer el archivo Excel
df = pd.read_excel(input_file)

# Filtrar las columnas necesarias
df_filtered = df[['New Name', 'Cleaned Sequence']]

# Eliminar duplicados basándose en 'Cleaned Sequence'
df_unique = df_filtered.drop_duplicates(subset='Cleaned Sequence')

# Escribir el archivo FASTA
with open(fasta_output_file, 'w') as fasta_file:
    for index, row in df_unique.iterrows():
        fasta_file.write(f">{row['New Name']}\n")
        fasta_file.write(f"{row['Cleaned Sequence']}\n")

print(f"Archivo FASTA generado con éxito: {fasta_output_file}")

# Crear diccionario desde el archivo FASTA y guardarlo en un archivo TXT
with open(fasta_output_file, 'r') as fasta_file, open(dict_output_file_epitopos, 'w') as dict_file:
    fasta_dict = {}
    name = None

    for line in fasta_file:
        line = line.strip()  # Eliminar espacios y saltos de línea
        if line.startswith(">"):
            # Es una línea con el nombre de la secuencia
            name = line[1:]  # Quitar el ">" al principio
        else:
            # Es una línea con la secuencia
            fasta_dict[name] = line
            dict_file.write(f"{name}: {line}\n")

print(f"Archivo TXT con diccionario generado con éxito: {dict_output_file_epitopos}")

 
#Paso 3: Comparacion diccionarios alfa sinucleina con epitopos predichos
# Función para leer un diccionario desde un archivo y devolverlo como un diccionario de Python
def leer_diccionario(ruta_archivo):
    diccionario = {}
    with open(ruta_archivo, 'r') as archivo:
        for linea in archivo:
            clave, secuencia = linea.strip().split(": ")
            diccionario[clave] = secuencia
    return diccionario

# Función para buscar coincidencias exactas entre dos diccionarios y también registrar las no coincidencias
def buscar_coincidencias(diccionario1, diccionario2):
    coincidencias = []
    no_coincidencias = []
    
    for clave1, secuencia1 in diccionario1.items():
        encontrada = False
        for clave2, secuencia2 in diccionario2.items():
            if secuencia1 == secuencia2:
                coincidencias.append((clave1, clave2, secuencia1))
                encontrada = True
                break
        if not encontrada:
            no_coincidencias.append((clave1, secuencia1))
    
    return coincidencias, no_coincidencias

# Función para guardar las coincidencias en un archivo de texto en formato diccionario
def guardar_coincidencias_txt(coincidencias, ruta_salida):
    with open(ruta_salida, 'w') as archivo_salida:
        for clave1, clave2, secuencia in coincidencias:
            archivo_salida.write(f"{clave1}: {secuencia}\n")

# Función para guardar coincidencias y no coincidencias en un archivo Excel 
def guardar_en_excel(coincidencias, no_coincidencias, ruta_excel):
    # Crear DataFrame para coincidencias
    df_coincidencias = pd.DataFrame(coincidencias, columns=['Clave Diccionario 1', 'Clave Diccionario 2', 'Secuencia'])
    
    # Crear DataFrame para no coincidencias
    df_no_coincidencias = pd.DataFrame(no_coincidencias, columns=['Clave Diccionario 1', 'Secuencia'])
    
    # Guardar ambos DataFrames en un archivo Excel
    with pd.ExcelWriter(ruta_excel, engine='openpyxl') as writer:
        df_coincidencias.to_excel(writer, sheet_name='Coincidencias', index=False)
        df_no_coincidencias.to_excel(writer, sheet_name='No Coincidencias', index=False)

# Rutas de los diccionarios
ruta_diccionario1 = dict_output_file_epitopos
ruta_diccionario2 = output_dict_path_1 

# Cargar los dos diccionarios
diccionario1 = leer_diccionario(ruta_diccionario1)
diccionario2 = leer_diccionario(ruta_diccionario2)

# Buscar coincidencias y no coincidencias
coincidencias, no_coincidencias = buscar_coincidencias(diccionario1, diccionario2)

# Guardar coincidencias en un archivo de texto
coincidencias_diccionario_epitopos = r"C:\Users\dennys\Desktop\Resultados oficiales MHC binding prediction\Coincidencias Epítopos predichos AlphaSyn.txt"
guardar_coincidencias_txt(coincidencias, coincidencias_diccionario_epitopos)

# Guardar coincidencias y no coincidencias en un archivo Excel
ruta_excel_salida = r"C:\Users\dennys\Desktop\Resultados oficiales MHC binding prediction\Coincidencias Epítopos predichos AlphaSyn.xlsx"
guardar_en_excel(coincidencias, no_coincidencias, ruta_excel_salida)

print("El proceso ha finalizado correctamente. Los resultados han sido guardados.")

# Paso 4: Comparación coincidencias epítopos predichos con proteoma de bacterias
# Función para convertir un archivo FASTA a diccionario
def fasta_to_dict(file_path):
    fasta_dict = {}
    with open(file_path, 'r') as file:
        sequence_id = None
        sequence = []

        for line in file:
            line = line.strip()
            if line.startswith('>'):  # Línea de encabezado
                if sequence_id is not None:  # Guardar la secuencia anterior
                    fasta_dict[sequence_id] = ''.join(sequence)
                sequence_id = line[1:].split()[0]  # Obtener el ID de la secuencia
                sequence = []  # Reiniciar la lista de secuencia
            else:
                sequence.append(line)  # Agregar líneas de secuencia

        # Guardar la última secuencia en el diccionario
        if sequence_id is not None:
            fasta_dict[sequence_id] = ''.join(sequence)

    return fasta_dict

# Función para cargar un diccionario desde un archivo TXT
def cargar_diccionario(archivo):
    diccionario = {}
    try:
        with open(archivo, 'r') as f:
            for linea in f:
                linea = linea.strip()
                if linea and ": " in linea:
                    nombre, secuencia = linea.split(": ", 1)
                    diccionario[nombre] = secuencia
    except FileNotFoundError as e:
        print(f"Error: {e}")
    return diccionario

# Función para remover modificaciones PTM
def remover_modificaciones(secuencia):
    return re.sub(r"\s*\+.*", "", secuencia)

# Convertir el archivo FASTA a diccionario
input_file_path = r"C:\Users\dennys\Desktop\Resultados oficiales MHC binding prediction\UP000406184 F. prausnitzii.fasta"
proteome_dict = fasta_to_dict(input_file_path)

# Guardar el diccionario de secuencias proteicas 
output_file_path = r"C:\Users\dennys\Desktop\Resultados oficiales MHC binding prediction\Proteoma diccionario F. prausnitzii.txt"
with open(output_file_path, 'w') as file:
    for key, value in proteome_dict.items():
        file.write(f"{key}: {value}\n")  # Formato: "nombre: secuencia"

# Cargar los diccionarios y comparar
archivo_diccionario1 = coincidencias_diccionario_epitopos  # Diccionario del paso 2
archivo_diccionario2 = output_file_path  # Usar el diccionario que acabamos de generar

# Rutas para guardar los resultados
archivo_salida_txt = r"C:\Users\dennys\Desktop\Resultados oficiales MHC binding prediction\Resultados comparacion F. prausnitzii.txt"
archivo_salida_excel = r"C:\Users\dennys\Desktop\Resultados oficiales MHC binding prediction\Resultados comparacion F. prausnitzii.xlsx"
archivo_salida_diccionario_coincidentes = r"C:\Users\dennys\Desktop\Resultados oficiales MHC binding prediction\Resultados comparacion F. prausnitzii.txt"

# Cargar diccionarios
diccionario1 = cargar_diccionario(archivo_diccionario1)
diccionario2 = cargar_diccionario(archivo_diccionario2)

# Crear diccionarios sin modificaciones PTM
diccionario1_sin_modificaciones = {nombre: remover_modificaciones(secuencia) for nombre, secuencia in diccionario1.items()}
diccionario2_sin_modificaciones = {nombre: remover_modificaciones(secuencia) for nombre, secuencia in diccionario2.items()}

# Comparar las secuencias
secuencias_coincidentes_exactas = []
secuencias_coincidentes_parciales = []
secuencias_no_en_diccionario2 = []
diccionario_coincidentes = {}

for nombre1, secuencia1 in diccionario1_sin_modificaciones.items():
    coincidencia_exacta = False
    coincidencia_parcial = False
    
    for nombre2, secuencia2 in diccionario2_sin_modificaciones.items():
        if secuencia1 == secuencia2:
            secuencias_coincidentes_exactas.append((nombre1, diccionario1[nombre1]))  # Usamos la secuencia original
            diccionario_coincidentes[nombre1] = diccionario1[nombre1]
            coincidencia_exacta = True
            break
        elif secuencia1 in secuencia2 or secuencia2 in secuencia1:
            secuencias_coincidentes_parciales.append((nombre1, diccionario1[nombre1], nombre2, diccionario2[nombre2]))  # Guardar las originales
            diccionario_coincidentes[nombre1] = diccionario1[nombre1]
            coincidencia_parcial = True
    
    if not coincidencia_exacta and not coincidencia_parcial:
        secuencias_no_en_diccionario2.append((nombre1, diccionario1[nombre1]))  # Guardar la original

# Guardar resultados en un archivo TXT
with open(archivo_salida_txt, 'w') as f:
    f.write("Péptidos con secuencias coincidentes exactas:\n")
    for nombre, secuencia in secuencias_coincidentes_exactas:
        f.write(f"{nombre}: {secuencia}\n")
    
    f.write("\nPéptidos con coincidencias parciales:\n")
    for nombre1, secuencia1, nombre2, secuencia2 in secuencias_coincidentes_parciales:
        f.write(f"{nombre1}: {secuencia1} (Coincide parcialmente con {nombre2}: {secuencia2})\n")
    
    f.write("\nPéptidos que NO coinciden en el segundo diccionario:\n")
    for nombre, secuencia in secuencias_no_en_diccionario2:
        f.write(f"{nombre}: {secuencia}\n")

# Guardar resultados en un archivo Excel
resultados = {
    "Coincidentes Exactos": pd.DataFrame(secuencias_coincidentes_exactas, columns=["Nombre", "Secuencia"]),
    "Coincidencias Parciales": pd.DataFrame(secuencias_coincidentes_parciales, columns=["Nombre Dic1", "Secuencia Dic1", "Nombre Dic2", "Secuencia Dic2"]),
    "No Coincidentes": pd.DataFrame(secuencias_no_en_diccionario2, columns=["Nombre", "Secuencia"]),
}

with pd.ExcelWriter(archivo_salida_excel, engine='openpyxl') as writer:
    resultados["Coincidentes Exactos"].to_excel(writer, sheet_name="Coincidentes Exactos", index=False)
    resultados["Coincidencias Parciales"].to_excel(writer, sheet_name="Coincidencias Parciales", index=False)
    resultados["No Coincidentes"].to_excel(writer, sheet_name="No Coincidentes", index=False)

# Guardar el diccionario de coincidentes en un archivo TXT
with open(archivo_salida_diccionario_coincidentes, 'w') as archivo_coincidentes:
    for nombre, secuencia in diccionario_coincidentes.items():
        archivo_coincidentes.write(f"{nombre}: {secuencia}\n")

# Mensaje de confirmación
print(f"Los resultados se han guardado en {archivo_salida_txt}, {archivo_salida_excel}, y {archivo_salida_diccionario_coincidentes}.")

# Paso 4: Identificar alelos de las coincidencias (En caso de que existan coincidencias)
# Ruta del archivo TXT y Excel
txt_file_path = archivo_salida_diccionario_coincidentes 
excel_file_path = output_excel_path_renombrados 

# Leer el archivo TXT en un diccionario
peptide_dict = {}
with open(txt_file_path, 'r') as f:
    for line in f:
        # Separar el nombre del péptido y la secuencia
        name, sequence = line.strip().split(":")
        peptide_dict[name.strip()] = sequence.strip()

# Leer el archivo Excel
df = pd.read_excel(excel_file_path)

# Limpiar los nombres de las columnas del DataFrame
df.columns = df.columns.str.strip()

# Filtrar las filas del archivo Excel donde las secuencias de la columna "core" coincidan con las del archivo TXT
# Guardar las coincidencias en un nuevo DataFrame
matches_df = df[df['peptide'].isin(peptide_dict.values())]

# Guardar las coincidencias en un nuevo archivo Excel
output_excel_path = r"C:\Users\dennys\Desktop\Resultados oficiales MHC binding prediction\Coincidencias F. prausnitzii.xlsx"
matches_df.to_excel(output_excel_path, index=False)

# Imprimir el número de coincidencias encontradas y la ruta del archivo guardado
print(f"Se encontraron {len(matches_df)} coincidencias.")
print(f"Archivo Excel guardado en: {output_excel_path}")
